{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from keras.layers.core import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('data2.csv')\n",
    "# X: independent variable matrix & y: dependent variable vector\n",
    "X = dataset.iloc[:,1:7].values\n",
    "# X = pd.DataFrame(X)\n",
    "Y  = dataset.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 86 entries, 0 to 85\n",
      "Data columns (total 7 columns):\n",
      "sales_rank        86 non-null int64\n",
      "overall_rating    86 non-null float64\n",
      "positive          86 non-null int64\n",
      "negative          86 non-null int64\n",
      "no_of_reviews     86 non-null int64\n",
      "discount_value    86 non-null float64\n",
      "discount_rate     86 non-null int64\n",
      "dtypes: float64(2), int64(5)\n",
      "memory usage: 4.8 KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deepanshu/anaconda3/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the ANN\n",
    "model = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "model.add(Dense(6, kernel_initializer = 'normal' , activation = 'relu', input_dim = 6))    \n",
    "\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "# Adding another hidden layer \n",
    "model.add(Dense(3, kernel_initializer = 'normal', activation = 'relu'))\n",
    "\n",
    "# Adding the output layer \n",
    "model.add(Dense(units= 1, kernel_initializer = 'normal', activation = 'linear'))        \n",
    "\n",
    "# Compiling the ANN\n",
    "model.compile(optimizer = 'rmsprop', loss = 'mse', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_27 (Dense)             (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 3)                 21        \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 67\n",
      "Trainable params: 67\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 61 samples, validate on 7 samples\n",
      "Epoch 1/100\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 70200.2298 - acc: 0.0000e+00 - val_loss: 21044.3965 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "61/61 [==============================] - 0s 694us/step - loss: 70153.6581 - acc: 0.0000e+00 - val_loss: 20996.3418 - val_acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "61/61 [==============================] - 0s 744us/step - loss: 70094.7216 - acc: 0.0164 - val_loss: 20923.1875 - val_acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      "61/61 [==============================] - 0s 976us/step - loss: 69993.2184 - acc: 0.0000e+00 - val_loss: 20864.0488 - val_acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      "61/61 [==============================] - 0s 968us/step - loss: 69901.4217 - acc: 0.0000e+00 - val_loss: 20771.3418 - val_acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      "61/61 [==============================] - 0s 744us/step - loss: 69781.1017 - acc: 0.0164 - val_loss: 20647.6816 - val_acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "61/61 [==============================] - 0s 881us/step - loss: 69606.0856 - acc: 0.0164 - val_loss: 20509.7988 - val_acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "61/61 [==============================] - 0s 657us/step - loss: 69467.9900 - acc: 0.0000e+00 - val_loss: 20307.6816 - val_acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      "61/61 [==============================] - 0s 862us/step - loss: 69202.0656 - acc: 0.0164 - val_loss: 20135.7910 - val_acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "61/61 [==============================] - 0s 691us/step - loss: 68939.4747 - acc: 0.0000e+00 - val_loss: 19935.1035 - val_acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      "61/61 [==============================] - 0s 753us/step - loss: 68773.5339 - acc: 0.0000e+00 - val_loss: 19813.8887 - val_acc: 0.0000e+00\n",
      "Epoch 12/100\n",
      "61/61 [==============================] - 0s 770us/step - loss: 68574.0978 - acc: 0.0164 - val_loss: 19592.6035 - val_acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      "61/61 [==============================] - 0s 671us/step - loss: 68401.1212 - acc: 0.0000e+00 - val_loss: 19479.0664 - val_acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      "61/61 [==============================] - 0s 789us/step - loss: 68172.9246 - acc: 0.0000e+00 - val_loss: 19257.9336 - val_acc: 0.0000e+00\n",
      "Epoch 15/100\n",
      "61/61 [==============================] - 0s 678us/step - loss: 68098.1912 - acc: 0.0000e+00 - val_loss: 19042.6270 - val_acc: 0.0000e+00\n",
      "Epoch 16/100\n",
      "61/61 [==============================] - 0s 796us/step - loss: 67594.4126 - acc: 0.0000e+00 - val_loss: 18784.1895 - val_acc: 0.0000e+00\n",
      "Epoch 17/100\n",
      "61/61 [==============================] - 0s 876us/step - loss: 67511.4841 - acc: 0.0000e+00 - val_loss: 18500.9863 - val_acc: 0.0000e+00\n",
      "Epoch 18/100\n",
      "61/61 [==============================] - 0s 676us/step - loss: 67131.2899 - acc: 0.0000e+00 - val_loss: 18190.1875 - val_acc: 0.0000e+00\n",
      "Epoch 19/100\n",
      "61/61 [==============================] - 0s 801us/step - loss: 66832.8876 - acc: 0.0000e+00 - val_loss: 17911.0840 - val_acc: 0.0000e+00\n",
      "Epoch 20/100\n",
      "61/61 [==============================] - 0s 730us/step - loss: 66404.5133 - acc: 0.0000e+00 - val_loss: 17789.3340 - val_acc: 0.0000e+00\n",
      "Epoch 21/100\n",
      "61/61 [==============================] - 0s 723us/step - loss: 66319.8017 - acc: 0.0000e+00 - val_loss: 17633.6230 - val_acc: 0.0000e+00\n",
      "Epoch 22/100\n",
      "61/61 [==============================] - 0s 869us/step - loss: 66209.9257 - acc: 0.0000e+00 - val_loss: 17546.9238 - val_acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      "61/61 [==============================] - 0s 705us/step - loss: 66078.2131 - acc: 0.0000e+00 - val_loss: 17304.5586 - val_acc: 0.0000e+00\n",
      "Epoch 24/100\n",
      "61/61 [==============================] - 0s 713us/step - loss: 65594.9597 - acc: 0.0000e+00 - val_loss: 17108.5195 - val_acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      "61/61 [==============================] - 0s 759us/step - loss: 65841.1185 - acc: 0.0000e+00 - val_loss: 17014.9082 - val_acc: 0.0000e+00\n",
      "Epoch 26/100\n",
      "61/61 [==============================] - 0s 725us/step - loss: 65420.6186 - acc: 0.0000e+00 - val_loss: 16912.3125 - val_acc: 0.0000e+00\n",
      "Epoch 27/100\n",
      "61/61 [==============================] - 0s 684us/step - loss: 65164.7558 - acc: 0.0000e+00 - val_loss: 16741.4902 - val_acc: 0.0000e+00\n",
      "Epoch 28/100\n",
      "61/61 [==============================] - 0s 741us/step - loss: 64927.0142 - acc: 0.0000e+00 - val_loss: 16548.0352 - val_acc: 0.0000e+00\n",
      "Epoch 29/100\n",
      "61/61 [==============================] - 0s 684us/step - loss: 64220.7453 - acc: 0.0000e+00 - val_loss: 16357.6279 - val_acc: 0.0000e+00\n",
      "Epoch 30/100\n",
      "61/61 [==============================] - 0s 749us/step - loss: 63816.4991 - acc: 0.0000e+00 - val_loss: 16142.7783 - val_acc: 0.0000e+00\n",
      "Epoch 31/100\n",
      "61/61 [==============================] - 0s 699us/step - loss: 64116.8971 - acc: 0.0000e+00 - val_loss: 16133.6855 - val_acc: 0.0000e+00\n",
      "Epoch 32/100\n",
      "61/61 [==============================] - 0s 668us/step - loss: 63910.1077 - acc: 0.0164 - val_loss: 16019.2969 - val_acc: 0.0000e+00\n",
      "Epoch 33/100\n",
      "61/61 [==============================] - 0s 696us/step - loss: 63953.6052 - acc: 0.0000e+00 - val_loss: 15914.9902 - val_acc: 0.0000e+00\n",
      "Epoch 34/100\n",
      "61/61 [==============================] - 0s 621us/step - loss: 62482.4985 - acc: 0.0000e+00 - val_loss: 15686.6807 - val_acc: 0.0000e+00\n",
      "Epoch 35/100\n",
      "61/61 [==============================] - 0s 704us/step - loss: 62741.8240 - acc: 0.0000e+00 - val_loss: 15392.3174 - val_acc: 0.1429\n",
      "Epoch 36/100\n",
      "61/61 [==============================] - 0s 739us/step - loss: 63013.3975 - acc: 0.0000e+00 - val_loss: 15299.8506 - val_acc: 0.0000e+00\n",
      "Epoch 37/100\n",
      "61/61 [==============================] - 0s 657us/step - loss: 61214.7546 - acc: 0.0000e+00 - val_loss: 15104.8145 - val_acc: 0.0000e+00\n",
      "Epoch 38/100\n",
      "61/61 [==============================] - 0s 729us/step - loss: 61499.3847 - acc: 0.0164 - val_loss: 14979.6982 - val_acc: 0.0000e+00\n",
      "Epoch 39/100\n",
      "61/61 [==============================] - 0s 680us/step - loss: 61141.1050 - acc: 0.0000e+00 - val_loss: 14811.9971 - val_acc: 0.0000e+00\n",
      "Epoch 40/100\n",
      "61/61 [==============================] - 0s 688us/step - loss: 60703.0653 - acc: 0.0164 - val_loss: 14730.5342 - val_acc: 0.0000e+00\n",
      "Epoch 41/100\n",
      "61/61 [==============================] - 0s 1ms/step - loss: 60880.6538 - acc: 0.0000e+00 - val_loss: 14530.6348 - val_acc: 0.0000e+00\n",
      "Epoch 42/100\n",
      "61/61 [==============================] - 0s 708us/step - loss: 59817.1726 - acc: 0.0328 - val_loss: 14257.8105 - val_acc: 0.0000e+00\n",
      "Epoch 43/100\n",
      "61/61 [==============================] - 0s 723us/step - loss: 59844.9226 - acc: 0.0000e+00 - val_loss: 14080.0850 - val_acc: 0.0000e+00\n",
      "Epoch 44/100\n",
      "61/61 [==============================] - 0s 761us/step - loss: 58246.4694 - acc: 0.0000e+00 - val_loss: 13843.6963 - val_acc: 0.0000e+00\n",
      "Epoch 45/100\n",
      "61/61 [==============================] - 0s 726us/step - loss: 58151.4945 - acc: 0.0164 - val_loss: 13633.9287 - val_acc: 0.0000e+00\n",
      "Epoch 46/100\n",
      "61/61 [==============================] - 0s 661us/step - loss: 57941.4649 - acc: 0.0000e+00 - val_loss: 13352.7324 - val_acc: 0.0000e+00\n",
      "Epoch 47/100\n",
      "61/61 [==============================] - 0s 655us/step - loss: 56856.1425 - acc: 0.0000e+00 - val_loss: 13170.3545 - val_acc: 0.0000e+00\n",
      "Epoch 48/100\n",
      "61/61 [==============================] - 0s 686us/step - loss: 55107.0065 - acc: 0.0164 - val_loss: 12962.2764 - val_acc: 0.0000e+00\n",
      "Epoch 49/100\n",
      "61/61 [==============================] - 0s 655us/step - loss: 55073.9387 - acc: 0.0000e+00 - val_loss: 12867.5020 - val_acc: 0.0000e+00\n",
      "Epoch 50/100\n",
      "61/61 [==============================] - 0s 763us/step - loss: 53847.1033 - acc: 0.0164 - val_loss: 12517.3643 - val_acc: 0.0000e+00\n",
      "Epoch 51/100\n",
      "61/61 [==============================] - 0s 664us/step - loss: 53331.3253 - acc: 0.0000e+00 - val_loss: 12346.3135 - val_acc: 0.0000e+00\n",
      "Epoch 52/100\n",
      "61/61 [==============================] - 0s 689us/step - loss: 52225.5469 - acc: 0.0000e+00 - val_loss: 12226.0469 - val_acc: 0.0000e+00\n",
      "Epoch 53/100\n",
      "61/61 [==============================] - 0s 729us/step - loss: 53137.9656 - acc: 0.0000e+00 - val_loss: 12023.4678 - val_acc: 0.0000e+00\n",
      "Epoch 54/100\n",
      "61/61 [==============================] - 0s 685us/step - loss: 53485.4299 - acc: 0.0000e+00 - val_loss: 11876.0850 - val_acc: 0.0000e+00\n",
      "Epoch 55/100\n",
      "61/61 [==============================] - 0s 658us/step - loss: 51619.8717 - acc: 0.0000e+00 - val_loss: 11675.8643 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "61/61 [==============================] - 0s 734us/step - loss: 51361.2331 - acc: 0.0000e+00 - val_loss: 11496.8887 - val_acc: 0.0000e+00\n",
      "Epoch 57/100\n",
      "61/61 [==============================] - 0s 671us/step - loss: 50464.1026 - acc: 0.0164 - val_loss: 11415.6455 - val_acc: 0.0000e+00\n",
      "Epoch 58/100\n",
      "61/61 [==============================] - 0s 698us/step - loss: 48150.8265 - acc: 0.0000e+00 - val_loss: 11251.2275 - val_acc: 0.0000e+00\n",
      "Epoch 59/100\n",
      "61/61 [==============================] - 0s 644us/step - loss: 47813.0566 - acc: 0.0000e+00 - val_loss: 11087.6240 - val_acc: 0.0000e+00\n",
      "Epoch 60/100\n",
      "61/61 [==============================] - 0s 639us/step - loss: 48437.4026 - acc: 0.0000e+00 - val_loss: 10961.0391 - val_acc: 0.0000e+00\n",
      "Epoch 61/100\n",
      "61/61 [==============================] - 0s 671us/step - loss: 46797.0357 - acc: 0.0164 - val_loss: 10785.9717 - val_acc: 0.0000e+00\n",
      "Epoch 62/100\n",
      "61/61 [==============================] - 0s 734us/step - loss: 47528.8768 - acc: 0.0000e+00 - val_loss: 10682.3271 - val_acc: 0.0000e+00\n",
      "Epoch 63/100\n",
      "61/61 [==============================] - 0s 849us/step - loss: 46056.7885 - acc: 0.0164 - val_loss: 10590.5400 - val_acc: 0.0000e+00\n",
      "Epoch 64/100\n",
      "61/61 [==============================] - 0s 702us/step - loss: 45237.8573 - acc: 0.0000e+00 - val_loss: 10499.4355 - val_acc: 0.0000e+00\n",
      "Epoch 65/100\n",
      "61/61 [==============================] - 0s 628us/step - loss: 43098.8404 - acc: 0.0000e+00 - val_loss: 10380.6025 - val_acc: 0.0000e+00\n",
      "Epoch 66/100\n",
      "61/61 [==============================] - 0s 683us/step - loss: 42801.2935 - acc: 0.0000e+00 - val_loss: 10290.9277 - val_acc: 0.0000e+00\n",
      "Epoch 67/100\n",
      "61/61 [==============================] - 0s 686us/step - loss: 42339.0380 - acc: 0.0000e+00 - val_loss: 10232.8857 - val_acc: 0.0000e+00\n",
      "Epoch 68/100\n",
      "61/61 [==============================] - 0s 667us/step - loss: 41637.1925 - acc: 0.0000e+00 - val_loss: 10166.7373 - val_acc: 0.1429\n",
      "Epoch 69/100\n",
      "61/61 [==============================] - 0s 638us/step - loss: 41321.5921 - acc: 0.0000e+00 - val_loss: 10156.9971 - val_acc: 0.0000e+00\n",
      "Epoch 70/100\n",
      "61/61 [==============================] - 0s 691us/step - loss: 39218.0128 - acc: 0.0000e+00 - val_loss: 10103.6006 - val_acc: 0.0000e+00\n",
      "Epoch 71/100\n",
      "61/61 [==============================] - 0s 689us/step - loss: 38717.8734 - acc: 0.0000e+00 - val_loss: 10127.4688 - val_acc: 0.0000e+00\n",
      "Epoch 72/100\n",
      "61/61 [==============================] - 0s 785us/step - loss: 38428.9302 - acc: 0.0000e+00 - val_loss: 10107.1592 - val_acc: 0.0000e+00\n",
      "Epoch 73/100\n",
      "61/61 [==============================] - 0s 707us/step - loss: 39203.3984 - acc: 0.0000e+00 - val_loss: 10110.2432 - val_acc: 0.0000e+00\n",
      "Epoch 74/100\n",
      "61/61 [==============================] - 0s 764us/step - loss: 39605.7971 - acc: 0.0000e+00 - val_loss: 10199.5645 - val_acc: 0.0000e+00\n",
      "Epoch 75/100\n",
      "61/61 [==============================] - 0s 700us/step - loss: 38276.5584 - acc: 0.0000e+00 - val_loss: 10200.2637 - val_acc: 0.0000e+00\n",
      "Epoch 76/100\n",
      "61/61 [==============================] - 0s 719us/step - loss: 37558.3394 - acc: 0.0000e+00 - val_loss: 10263.7051 - val_acc: 0.0000e+00\n",
      "Epoch 77/100\n",
      "61/61 [==============================] - 0s 887us/step - loss: 36127.2296 - acc: 0.0000e+00 - val_loss: 10381.5537 - val_acc: 0.0000e+00\n",
      "Epoch 78/100\n",
      "61/61 [==============================] - 0s 712us/step - loss: 37835.7620 - acc: 0.0000e+00 - val_loss: 10463.6230 - val_acc: 0.0000e+00\n",
      "Epoch 79/100\n",
      "61/61 [==============================] - 0s 733us/step - loss: 35292.3188 - acc: 0.0000e+00 - val_loss: 10460.3936 - val_acc: 0.0000e+00\n",
      "Epoch 80/100\n",
      "61/61 [==============================] - 0s 878us/step - loss: 34647.4370 - acc: 0.0000e+00 - val_loss: 10547.7559 - val_acc: 0.0000e+00\n",
      "Epoch 81/100\n",
      "61/61 [==============================] - 0s 697us/step - loss: 37774.9659 - acc: 0.0000e+00 - val_loss: 10427.5342 - val_acc: 0.0000e+00\n",
      "Epoch 82/100\n",
      "61/61 [==============================] - 0s 735us/step - loss: 34539.4682 - acc: 0.0000e+00 - val_loss: 10571.9541 - val_acc: 0.0000e+00\n",
      "Epoch 83/100\n",
      "61/61 [==============================] - 0s 830us/step - loss: 32950.0260 - acc: 0.0000e+00 - val_loss: 10751.4238 - val_acc: 0.0000e+00\n",
      "Epoch 84/100\n",
      "61/61 [==============================] - 0s 799us/step - loss: 33138.7480 - acc: 0.0000e+00 - val_loss: 10870.4004 - val_acc: 0.0000e+00\n",
      "Epoch 85/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 48990.0977 - acc: 0.0000e+0 - 0s 815us/step - loss: 33648.6577 - acc: 0.0000e+00 - val_loss: 10995.9893 - val_acc: 0.0000e+00\n",
      "Epoch 86/100\n",
      "61/61 [==============================] - 0s 729us/step - loss: 32740.3837 - acc: 0.0000e+00 - val_loss: 11241.6045 - val_acc: 0.0000e+00\n",
      "Epoch 87/100\n",
      "61/61 [==============================] - 0s 914us/step - loss: 32122.1567 - acc: 0.0000e+00 - val_loss: 11313.2549 - val_acc: 0.0000e+00\n",
      "Epoch 88/100\n",
      "61/61 [==============================] - 0s 769us/step - loss: 32984.6693 - acc: 0.0000e+00 - val_loss: 11295.3672 - val_acc: 0.0000e+00\n",
      "Epoch 89/100\n",
      "61/61 [==============================] - 0s 771us/step - loss: 32815.8640 - acc: 0.0000e+00 - val_loss: 11126.7607 - val_acc: 0.0000e+00\n",
      "Epoch 90/100\n",
      "61/61 [==============================] - 0s 800us/step - loss: 32555.8747 - acc: 0.0328 - val_loss: 11166.3730 - val_acc: 0.0000e+00\n",
      "Epoch 91/100\n",
      "61/61 [==============================] - 0s 727us/step - loss: 34422.1959 - acc: 0.0000e+00 - val_loss: 11264.3281 - val_acc: 0.0000e+00\n",
      "Epoch 92/100\n",
      "61/61 [==============================] - 0s 771us/step - loss: 33839.9964 - acc: 0.0000e+00 - val_loss: 11280.4365 - val_acc: 0.0000e+00\n",
      "Epoch 93/100\n",
      "61/61 [==============================] - 0s 618us/step - loss: 32543.5975 - acc: 0.0000e+00 - val_loss: 11313.8057 - val_acc: 0.0000e+00\n",
      "Epoch 94/100\n",
      "61/61 [==============================] - 0s 720us/step - loss: 32967.2305 - acc: 0.0000e+00 - val_loss: 11448.7188 - val_acc: 0.0000e+00\n",
      "Epoch 95/100\n",
      "61/61 [==============================] - 0s 689us/step - loss: 34142.8038 - acc: 0.0164 - val_loss: 11306.2949 - val_acc: 0.0000e+00\n",
      "Epoch 96/100\n",
      "61/61 [==============================] - 0s 878us/step - loss: 33584.4229 - acc: 0.0000e+00 - val_loss: 11221.5068 - val_acc: 0.0000e+00\n",
      "Epoch 97/100\n",
      "61/61 [==============================] - 0s 898us/step - loss: 32419.3007 - acc: 0.0000e+00 - val_loss: 11280.2764 - val_acc: 0.0000e+00\n",
      "Epoch 98/100\n",
      "61/61 [==============================] - 0s 958us/step - loss: 30966.8822 - acc: 0.0000e+00 - val_loss: 11388.1113 - val_acc: 0.0000e+00\n",
      "Epoch 99/100\n",
      "61/61 [==============================] - 0s 887us/step - loss: 31910.5866 - acc: 0.0164 - val_loss: 11560.8135 - val_acc: 0.0000e+00\n",
      "Epoch 100/100\n",
      "61/61 [==============================] - 0s 730us/step - loss: 31374.4270 - acc: 0.0000e+00 - val_loss: 11796.9980 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd5a5198fd0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the ANN to the training set \n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=10, validation_split=0.1, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predicting the test set result \n",
    "Y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  76.00236511],\n",
       "       [  22.3760891 ],\n",
       "       [  90.10124207],\n",
       "       [ 102.26125336],\n",
       "       [ 187.85597229],\n",
       "       [ 155.98670959],\n",
       "       [ 254.37680054],\n",
       "       [ 122.63972473],\n",
       "       [ 187.2389679 ],\n",
       "       [ 137.10496521],\n",
       "       [  94.60783386],\n",
       "       [  29.23841095],\n",
       "       [ 347.94116211],\n",
       "       [ 418.10195923],\n",
       "       [ 186.46185303],\n",
       "       [ 149.68965149],\n",
       "       [ 130.83702087],\n",
       "       [ 185.72279358]], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  9,  28,  96, 102, 148, 712,  35, 563, 266, 533,  22,  26,  20,\n",
       "       263,  74,  14,   8, 573])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average absolute error: 191.84 degrees.\n",
      "Accuracy: -346.12 %.\n"
     ]
    }
   ],
   "source": [
    "errors = abs(Y_pred - Y_test)\n",
    "\n",
    "print('Average absolute error:', round(np.mean(errors), 2), 'degrees.')\n",
    "\n",
    "# Calculate mean absolute percentage error (MAPE)\n",
    "mape = 100 * (errors / Y_test)\n",
    "\n",
    "# Calculate and display accuracy\n",
    "accuracy = 100 - np.mean(mape)\n",
    "print('Accuracy:', round(accuracy, 2), '%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree = ExtraTreesRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
       "          max_features='auto', max_leaf_nodes=None,\n",
       "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "          n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tree' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-9777841c6d18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tree' is not defined"
     ]
    }
   ],
   "source": [
    "print(tree.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names = list(dataset.columns[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imp = list(tree.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featureImportance = list(zip(names, imp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "importances = list(zip(tree.feature_importances_, names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.14751907421500249, 'overall_rating'),\n",
       " (0.18234953668276441, 'positive'),\n",
       " (0.12028841597319342, 'negative'),\n",
       " (0.22772865570612227, 'no_of_reviews'),\n",
       " (0.12581424841348957, 'discount_value'),\n",
       " (0.19630006900942795, 'discount_rate')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
